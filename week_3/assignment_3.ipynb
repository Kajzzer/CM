{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaj Meijer, 10509534\n",
    "\n",
    "# Lotte Philippus, 11291168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning\n",
    "\n",
    "Q-learning algorithmes zijn gebaseerd op de TD-learning modellen die we eerder hebben besproken. Q-learning leert direct de associatie tussen states, actions en outcomes. De robot gaat nu dus niet alleen maar belongingen krijgen maar ook uitzoeken welke handeling de beste is geveven de situatie. \n",
    "\n",
    "Details over Q-learning zijn terug te vinden in de college slides en het hoofdstuk van Gureckis & Love [**computational reinforcement learning**](http://bradlove.org/papers/GureckisLovePress.pdf) en voor meer verdieping in het online boek van [**Sutton & Barto**](http://incompleteideas.net/book/bookdraft2018jan1.pdf) en dan met name hoofdstuk 6.\n",
    "\n",
    "Het leren in deze opdracht speelt zich af in een simpel **Markov Decision Process** met de volgende structuur:\n",
    "\n",
    "![](bandit_arms.png)\n",
    "\n",
    "In deze taak moet de robot telkens uit een van de schatkisten iets pakken. In sommige schatkisten zit meer geld dan in anderen, maar de robot weet in het begin nog niks over de schatkisten, en verwacht er maar weinig van. In elke ronde wordt uitkomst van een schatkist bepaald door een trekking van een waarde uit een normaalverdeling.\n",
    "\n",
    "De uitkomsten van schatkisten verschillen in hun gemiddelde maar niet de variatie (standaard deviatie). \n",
    "\n",
    "**Let op:** In dit simpele experiment is er maar een state, waarin de robot telkens terugkeert na het maken van een keuze. Dit heeft als gevolg dat bij het leren geen rekening gehouden hoeft te worden met de actie in de volgende state gemaakt wordt. De standaard prediction-error:\n",
    "\n",
    "$$\\delta = r_{t+1} + \\gamma\\ max_a\\ Q(s_{t+1} , a) − Q(s_t , a_t)$$\n",
    "\n",
    "verandert dus simpelweg in:\n",
    "$$\\delta = r_{t+1} − Q(s_t , a_t)$$\n",
    "\n",
    "In het begin van het experiment heeft de robot geen enkele kennis van de wereld en geen enkele verwachtingen voor van het krijgen van beloningen. Voor elke schatkist geldt:\n",
    "\n",
    "$$Q(1)=Q(2)=Q(3)=Q(4)=0$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.a (5 punten)\n",
    "\n",
    "Schrijf de Q-learning functie op die de nieuwe waarde Q uitrekent nadat de robot een schatkist heeft uitgekozen. Welke vrije variabele heeft deze functie en wat is zijn rol in leren? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q is de leerwaarde.\n",
    "r is de beloning.\n",
    "s is de staat.\n",
    "a is de actie.\n",
    "alpha is de leersnelheid en is de vrije variabele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q(Q, r, s, a, alpha):\n",
    "    return Q[s, a] + alpha*(r - Q[s, a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.b (5 punten)\n",
    "\n",
    "Stel de robot selecteert schatkist 1 en vindt twee munten. Wat is hierna de waarde van Q(1)? rapporteer dit voor\n",
    "$\\alpha=0.5$ en $\\alpha=0.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]]\n",
      "[[0.  0.4 0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "def printQ(alpha):\n",
    "    \n",
    "    Q = np.zeros((1, 4))\n",
    "    s = 0\n",
    "    a = 1\n",
    "    r = 2\n",
    "    Q[s, a] = update_Q(Q, r, s, a, alpha)\n",
    "    print(Q)\n",
    "\n",
    "\n",
    "alpha = 0.5\n",
    "printQ(alpha)\n",
    "\n",
    "alpha = 0.2\n",
    "printQ(alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.c (10 punten)\n",
    "\n",
    "Schrijf een functie `q_learn` die als input, alpha ($\\alpha$), epsilon($\\epsilon$) en rondes (trials) accepteert. De output van deze functie moet een lijst met $Q$ waarden zijn voor elke schatkist (1 t/m 4) in de wereld van de robot na het leren van een aantal rondes. We gaan er nu van uit dat de robot de $\\epsilon$-greedy keuze regel toepast.\n",
    "\n",
    "* Initieer de verwachtingen van de robot voor de 4 keuzes:\n",
    "    * Q(1)=Q(2)=Q(3)=Q(4)=0. \n",
    "* Intieer total_score = 0\n",
    "* Initieer de beloningen voor de 4 schatkisten:\n",
    "    * K(1): mean=20, SD=4\n",
    "    * K(2): mean=30, SD=4\n",
    "    * K(3): mean=50, SD=4\n",
    "    * K(4): mean=70, SD=4\n",
    "* Creëer een for-loop over alle rondes:\n",
    "    * Elke ronde selecteert de robot een kist op basis van $\\epsilon$-greedy. Denk er aan bij explore een random kist, bij exploit de kist met hoogste Q-value (als er meerdere de hoogste waarde hebben, daar weer random uit kiezen). \n",
    "    * Kijk wat de beloning is na maken van een keuze, en update dan Q-value van die kist. \n",
    "* zorg dat deze functie de volgende lijsten als output heeft: final Q values, total_score, en voor elke schatkist een lijst wanneer deze gekozen werd (1 voor gekozen een 0 wanneer niet gekozen). Dit resulteert in 4 lijsten met keuzes die gebruikt kunnen worden voor het plotten van het gedrag van het model.\n",
    "\n",
    "\n",
    "Laat me behulp van deze functie de robot 200 rondes leren over deze wereld (1 leer episode bestaat dus uit 200 rondes). Hoe zien zijn verwachtingen (Q-values) voor de schatkisten aan het eind van het experiment er uit gegeven\n",
    "\n",
    "1. $\\alpha = 0.1$ en $\\epsilon = 0.1$\n",
    "2. $\\alpha = 0.5$ en $\\epsilon = 0.1$\n",
    "\n",
    "Laat voor beide modellen zien wat de totale verdiende score is gedurende de trails, wat de geleede Q-values zijn voor elke kist en plot hoe de keuzes voor de verschillende kisten veranderen gedurende de trails.\n",
    "\n",
    "Voor het plotten van keuzes is het handig om naar het gemiddels van bins van 10 trails tegelijk te kijken. Alvast wat code om je beetje op weg te helpen:\n",
    "```python\n",
    "# Width is de grote van elke bin\n",
    "width = 10\n",
    "# Hier knippen we de laatste (choicelist_1.size % width) elementen van de lijst\n",
    "# Dan reshapen we naar een matrix van X * width en nemen we de mean over de width axis\n",
    "# Hiermee krijgen we dus het gemiddelde aantal keer dat deze keuze gemaakt is voor width stappen\n",
    "result1 = choicelist_1[:(choicelist_1.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "plt.plot(result1, label=r\"$1$\")\n",
    "```\n",
    "\n",
    "Welk van de twee geleerde modellen zit dichter bij de waarheid op basis van deze resultaten?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 met $\\alpha = 0.5$ zit dichter bij de waarheid, want de Q-waarden zitten dichter bij de means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learn(alpha, epsilon, trials = 200):\n",
    "    \n",
    "    # initialize starting values\n",
    "    Q = np.zeros((1, 4))\n",
    "    total_score = 0\n",
    "    means = [20, 30, 50, 70] \n",
    "    SD = 4   \n",
    "    choices = np.zeros((4,trials))\n",
    "    \n",
    "    # loop over the trials\n",
    "    for trial in range(trials):\n",
    "\n",
    "        # choose action\n",
    "        if random.random() < epsilon:\n",
    "            \n",
    "            # random action\n",
    "            action = random.randint(0,3)\n",
    "        else:\n",
    "            \n",
    "            # greedy action\n",
    "            highest = max(Q[0])\n",
    "            options = [x for x in range(len(Q[0])) if Q[0, x] == highest]\n",
    "            action = random.choice(options)\n",
    "\n",
    "        # get the reward for the action\n",
    "        K = np.random.normal(means[action], SD)\n",
    "        \n",
    "        # update Q value\n",
    "        Q[0, action] = update_Q(Q, K, 0, action, alpha)\n",
    "\n",
    "        total_score += K\n",
    "        \n",
    "        choices[action, trial] = 1\n",
    "        \n",
    "    return Q, total_score, choices        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_q_learn(alpha, epsilon):\n",
    "    Q, total_score, choicelists = q_learn(alpha, epsilon)\n",
    "\n",
    "    print(Q)\n",
    "    print(total_score)\n",
    "\n",
    "    for i in range(len(choicelists)):\n",
    "        choicelist = choicelists[i]\n",
    "\n",
    "        # Width is de grote van elke bin\n",
    "        width = 10\n",
    "        # Hier knippen we de laatste (choicelist_1.size % width) elementen van de lijst\n",
    "        # Dan reshapen we naar een matrix van X * width en nemen we de mean over de width axis\n",
    "        # Hiermee krijgen we dus het gemiddelde aantal keer dat deze keuze gemaakt is voor width stappen\n",
    "        result = choicelist[:(choicelist.size // width * width)].reshape(-1, width).mean(axis=1)\n",
    "        plt.plot(result, label=r\"$\" + str(i + 1) + \"$\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.9895492  16.81737363  9.45984156 71.09787413]]\n",
      "13509.939598231735\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_q_learn(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14.00821705 29.17517809 46.8448104  70.07063653]]\n",
      "12901.740312199154\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_q_learn(0.5, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.d (10 punten)\n",
    "\n",
    "Laten we nu kijken hoe succesvol de verschillende strategieën (lees combinatie van parameter waardes) zijn. \n",
    "\n",
    "Schrijf nu een loop die `q_learn` 500 keer aanroept met een bepaalde parameter setting (en altijd 200 leerrondes) en sla telkens het totaal aantal punten op, zodat je aan het eind een lijst hebt van 500 totaal scores. \n",
    "\n",
    "Vergelijk het gemiddelde van die 500 totaalscores voor $\\alpha=0.1$, $\\alpha=0.3$ en $\\alpha=0.5$ met $\\epsilon=0.1$ voor alle experimenten. Leg uit hoe de verschillen tot stand komen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoe sneller de robot leert, hoe sneller hij de beste keuzes kan maken om zijn score te optimaliseren, dus een hogere leersnelheid resulteert in een hogere totale score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_score(alpha, epsilon = 0.1, episodes = 500):\n",
    "    result = []\n",
    "    for _ in range(episodes):\n",
    "        _, total_score, _ = q_learn(alpha, epsilon)\n",
    "        result.append(total_score)\n",
    "    \n",
    "    # get the average score below\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9866.464569431213"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_score(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11529.666131196353"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_score(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12314.835603540409"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_score(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration-Exploitation\n",
    "\n",
    "We gaan nu dieper in op het exploration vs. exploitation dilemma. Laten we eerst kijken hoe verschillende e parameters uitwerking hebben op het aantal punten dat gewonnen wordt. Gebruik hier de functie van q_learn van de vorige vraag met $\\epsilon=0.05$, $\\epsilon=0.2$ en $\\epsilon=0.6$ en met $\\alpha=0.3$ voor alle experimenten. \n",
    "\n",
    "### Q2.a (10 punten)\n",
    "\n",
    "Kijk voor elke parameter setting weer naar de gemiddelde totaal score van 500 leer episodes. Waar ligt ongeveer het optimale niveau van exploratie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het optimale niveau van exploratie ligt in deze 3 gevallen bij 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10945.99434940335"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_score(0.3, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12031.842949871314"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_score(0.3, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10558.601972876324"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_score(0.3, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.b (10 punten)\n",
    "\n",
    "Pas nu `q_learn` zo aan dat de parameter $\\epsilon$ gedurende een leer episode steeds kleiner wordt. Dit kan bijvoorbeeld door elke ronde $\\epsilon$ met een vast percentage te verkleinen (denk aan iets tussen 0 en 10%), maar andere manieren zijn ook mogelijk. Sla dit model op als `q_learn_decay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learn_decay(alpha, epsilon, trials = 200):\n",
    "    \n",
    "    # initialize starting values\n",
    "    Q = np.zeros((1, 4))\n",
    "    total_score = 0\n",
    "    means = [20, 30, 50, 70] \n",
    "    SD = 4   \n",
    "    choices = np.zeros((4,trials))\n",
    "    \n",
    "    # loop over the trials\n",
    "    for trial in range(trials):\n",
    "\n",
    "        # choose action\n",
    "        if random.random() < epsilon:\n",
    "            \n",
    "            # random action\n",
    "            action = random.randint(0,3)\n",
    "        else:\n",
    "            \n",
    "            # greedy action\n",
    "            highest = max(Q[0])\n",
    "            options = [x for x in range(len(Q[0])) if Q[0, x] == highest]\n",
    "            action = random.choice(options)\n",
    "\n",
    "        # get the reward for the action\n",
    "        K = np.random.normal(means[action], SD)\n",
    "        \n",
    "        # update Q value\n",
    "        Q[0, action] = update_Q(Q, K, 0, action, alpha)\n",
    "\n",
    "        total_score += K\n",
    "        \n",
    "        choices[action, trial] = 1\n",
    "        \n",
    "        epsilon *= 0.9\n",
    "        \n",
    "    return Q, total_score, choices        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.c (10 punten)\n",
    "\n",
    "Kijk nu naar een aantal beginwaarden voor parameter $\\epsilon$, en kijk welk model meer punten kan verdienen in de taak (verken hier waarden van $\\epsilon$ tussen .1 en .9). Gebruik weer het gemiddelde aantal punten over 500 leer episodes (en nog steeds 200 rondes per episode en $\\alpha =  0.3$). Welk model is het beste en waarom denk je dat dit zo is?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het model met epsilon = 0.9 is het beste model. Het begint met veel random stappen, dus hoge exploration, en later neemt hij door de decay steeds vaker de beste stappen, dus hoge exploitation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_score_decay(epsilon, alpha = 0.3, episodes = 500):\n",
    "    result = []\n",
    "    for _ in range(episodes):\n",
    "        _, total_score, _ = q_learn_decay(alpha, epsilon)\n",
    "        result.append(total_score)\n",
    "    \n",
    "    # get the average score below\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 9273.123481653674 for epsilon = 0.1\n",
      "The score is 9528.845213013592 for epsilon = 0.15000000000000002\n",
      "The score is 9695.508947243166 for epsilon = 0.2\n",
      "The score is 10229.586118170166 for epsilon = 0.25\n",
      "The score is 10524.626760643821 for epsilon = 0.30000000000000004\n",
      "The score is 10829.50733169034 for epsilon = 0.35\n",
      "The score is 10525.713243151777 for epsilon = 0.4\n",
      "The score is 10854.763968049732 for epsilon = 0.45000000000000007\n",
      "The score is 11151.903697043199 for epsilon = 0.5\n",
      "The score is 11312.62994122708 for epsilon = 0.55\n",
      "The score is 11552.041667596222 for epsilon = 0.6\n",
      "The score is 11725.176071511969 for epsilon = 0.65\n",
      "The score is 11951.875617117757 for epsilon = 0.7000000000000001\n",
      "The score is 11855.606565818984 for epsilon = 0.75\n",
      "The score is 12120.802849672262 for epsilon = 0.8\n",
      "The score is 12279.093014418768 for epsilon = 0.85\n",
      "The score is 12379.718997836 for epsilon = 0.9\n"
     ]
    }
   ],
   "source": [
    "epsilons = np.linspace(0.1, 0.9, 17)\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    a_s = average_score_decay(epsilon)\n",
    "    print(\"The score is\", a_s, \"for epsilon =\", epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Een andere zeer populaire methode om exploratie te implementeren is de softmax regel. Deze kan gebruikt worden om de waarschijnlijkheid uit te rekenen dat de robot een specifieke kist kiest. Bijvoorbeeld de waarschijnlijkheid dat de robot op een bepaald moment kist 1 kiest is:\n",
    "\n",
    "$$P(Q(1)) = \\frac{e(Q(1)*theta)}{\\sum_s e(Q(s)*theta)}$$\n",
    "\n",
    "Voor kist 2:\n",
    "\n",
    "$$P(Q(2)) = \\frac{e(Q(2)*theta)}{\\sum_s e(Q(s)*theta)}$$\n",
    "\n",
    "En natuurlijk:\n",
    "\n",
    "$$P(Q(1))+ P(Q(2)) +P(Q(3))+ P(Q(2)) = 1  (100\\%)$$\n",
    "\n",
    "want de robot kiest altijd een van de 4 opties, dus samen moeten dat 100% kans zijn.\n",
    "\n",
    "Implementeer nu de softmax regel in de `q_learn` functie en geef deze de naam `q_learn_softmax`.\n",
    "\n",
    "* Gebruik elke ronde de $P(Q)$ informatie om de robot een kist te laten kiezen.\n",
    "* Zorg ook dat deze elke ronde de waarschijnlijkheid $P(Q)$ van het kiezen van elke kist wordt opgeslagen zodat we hier later weer naar kunnen kijken. \n",
    "\n",
    "Gebruik dit model weer om de gemiddelde score voor 500 episodes voor verschillende waardes van theta (waardes tussen $0.01$ en $1$, op zn minst 5) met elkaar te vergelijken, met wederom 200 rondes per episode en een $\\alpha$ van $0.3$, gebruik makende van de methode die we hier boven ontwikkeld hebben. \n",
    "\n",
    "\n",
    "### Q3.a (10 punten)\n",
    "\n",
    "Wat is ongeveer de optimale waarde voor theta, hoe verhoud dit model zich tot de simpele versie van $\\epsilon$-greedy? Hoe gedraagt het model zicht met een hoge waarde van theta, en hoe met een lage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De optimale waarde voor theta is ongeveer 0.065. Rond de optimale waarde voor theta doet dit model het beter dan $\\epsilon$-greedy, maar voor de rest een stuk slechter. Bij een hoge waarde van theta doet dit model het slechter en bij een lagere waarde beter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Q, s, a, theta):\n",
    "    total = [np.exp(x*theta) for x in Q[s]]\n",
    "    return np.exp(Q[s, a]*theta)/sum(total)\n",
    "    \n",
    "\n",
    "def calculate_softmax(Q, theta):\n",
    "    P = np.zeros(Q.shape)\n",
    "    for action in range(len(Q[0])):\n",
    "        P[0,action] = softmax(Q, 0, action, theta)\n",
    "    return P\n",
    "\n",
    "def pick_action(P, rng):\n",
    "    \n",
    "    total = 0\n",
    "    \n",
    "    for index in range(len(P[0])):\n",
    "        \n",
    "        total += P[0, index]\n",
    "        \n",
    "        if total > rng:\n",
    "            return index\n",
    "        \n",
    "\n",
    "def q_learn_softmax(alpha, theta, trials = 200):\n",
    "    \n",
    "    # initialize starting values\n",
    "    Q = np.zeros((1, 4))\n",
    "    total_score = 0\n",
    "    means = [20, 30, 50, 70] \n",
    "    SD = 4   \n",
    "    choices = np.zeros((4,trials))\n",
    "    \n",
    "    # loop over the trials\n",
    "    for trial in range(trials):\n",
    "\n",
    "        # get the softmax values\n",
    "        P = calculate_softmax(Q, theta)\n",
    "        \n",
    "        rng = random.random()\n",
    "        action = pick_action(P, rng)\n",
    "\n",
    "        # get the reward for the action\n",
    "        K = np.random.normal(means[action], SD)\n",
    "        \n",
    "        # update Q value\n",
    "        Q[0, action] = update_Q(Q, K, 0, action, alpha)\n",
    "\n",
    "        total_score += K\n",
    "        \n",
    "        choices[action, trial] = 1\n",
    "        \n",
    "    return Q, total_score, choices    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_score_softmax(theta, alpha = 0.3, episodes = 500):\n",
    "    result = []\n",
    "    for _ in range(episodes):\n",
    "        _, total_score, _ = q_learn_softmax(alpha, theta)\n",
    "        result.append(total_score)\n",
    "    \n",
    "    # get the average score below\n",
    "    return sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10893.618033676239"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_score_softmax(0.1, 0.3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 9208.691241868015 for theta = 0.01\n",
      "The score is 12595.819994487192 for theta = 0.065\n",
      "The score is 12264.24121490115 for theta = 0.12\n",
      "The score is 11641.389481731821 for theta = 0.17500000000000002\n",
      "The score is 10815.454531903533 for theta = 0.23\n",
      "The score is 9855.417117237323 for theta = 0.28500000000000003\n",
      "The score is 9637.490853164792 for theta = 0.34\n",
      "The score is 9226.29283886445 for theta = 0.395\n",
      "The score is 8965.243430359908 for theta = 0.45\n",
      "The score is 8850.346878095117 for theta = 0.505\n",
      "The score is 9111.371149235181 for theta = 0.56\n",
      "The score is 8603.471156929108 for theta = 0.615\n",
      "The score is 8491.542697226856 for theta = 0.67\n",
      "The score is 8518.638870020784 for theta = 0.725\n",
      "The score is 8312.032797460768 for theta = 0.78\n",
      "The score is 8551.41396013682 for theta = 0.835\n",
      "The score is 8630.166932462682 for theta = 0.89\n",
      "The score is 8451.820408163687 for theta = 0.9450000000000001\n",
      "The score is 8481.955663293691 for theta = 1.0\n"
     ]
    }
   ],
   "source": [
    "thetas = np.linspace(0.01, 1, 19)\n",
    "\n",
    "for theta in thetas:\n",
    "    a_s = average_score_softmax(theta)\n",
    "    print(\"The score is\", a_s, \"for theta =\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "\n",
    "We gaan nu kijken naar de resultaten van een echt experiment. We hebben de data van een proefpersoon die het bovenstaande experiment heeft gespeeld. In de data file kunnen we terugvinden welke van de 4 opties zij gekozen had en hoeveel punten vervolgens elke trial verdient zijn. We gaan kijken met welke parameter waardes  Q-learning met een softmax choice rule het gedrag van de proefpersonen het beste kan voorspellen. De proefpersoon heeft 80 rondes gespeelt. \n",
    "\n",
    "Lees de data in uit *L4_data_1.txt* met behulp van [loadtxt](https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html):\n",
    "```python\n",
    "with open(\"L4_data_1.txt\") as f:\n",
    "    data = np.loadtxt(f, dtype=int, delimiter=\"\\t\", skiprows=1)\n",
    "```\n",
    "\n",
    "Pas de `q_learn_softmax` functie aan zodat je deze op de data van de proefpersonen kan fitten. (Zie LC1 voor details over hoe functies gefit moeten worden, en pseudo code onderaan voor meer hulp).\n",
    "\n",
    "Ga er van uit dat de proefpersonen enige ervaring hebben met dit type experiment en verwachten dat ze gemiddeld wel 40 punten per ronde gaan verdienen (alle Q’s starten op 40 ipv 0). \n",
    "\n",
    "We gaan voor het fitten van het model gebruik maken van minimize van scipy.optimize (`from scipy.optimize import minimize`) en we gaan proberen *Log Likelihood* te optimaliseren (mate van fit). \n",
    "\n",
    "Wat we op elke trial willen weten is wat de waarschijnlijkheid is dat het model dezelfde keuze maakte als de proefpersoon. Hoe groter de kans (likelihood) dat het model correct kiest, hoe beter het model \"fit\". \n",
    "\n",
    "In het databestand van de proefpersoon kunnen zien welke van de 4 kisten de proefpersoon koos. Dit kunnen we dan op elke ronde vergelijken met de corresponderende P(Q). In de eerste ronde zijn alle Q values nog gelijk dus zijn alle P(Q)s = .25.\n",
    "\n",
    "Voor de eerste ronde geld daarom automatisch dan waarschijnlijkheid (likelihood) van de keuze van de proefpersoon ook .25 is, maar dat gaat veranderen naarmate er geleerd wordt. \n",
    "\n",
    "In het databestand staat ook voor elke ronde wat de uitkomst van een keuze was, deze moet gebruikt worden om vervolgens de Q-values aan te passen, net als we eerder gedaan hebben in de simulaties.\n",
    "\n",
    "De output van deze functie moet de som van alle *log(P(Q(chosen)))* zijn. Let op vermenigvuldig deze som met -1. Dat doen we omdat minimize de functie probeert te minimaliseren , en we opzoek zijn naar de max LL (double negative). \n",
    "\n",
    "`**pseudo code**:`\n",
    "```python\n",
    "def q_learn_softmax_fit(params):\n",
    "    alpha, theta, init_value = params\n",
    "    nArms = 4\n",
    "    Q = np.array([init_value]*nArms)\n",
    "    LL = 0\n",
    "    \n",
    "    for row in data:\n",
    "        probs <- calculate probability of chosing each option based on theta, Qvalues and softmax\n",
    "        \n",
    "        choice <- read choice from data (each trial is one row in file)\n",
    "        outcome <- read outcomee of choice from data\n",
    "        \n",
    "        LL += np.log(probs[choice])\n",
    "        \n",
    "        Q[choice] <- update Q value\n",
    "    \n",
    "    # Scaled for minimize function\n",
    "    return -1*LL\n",
    "\n",
    "# minimize takes a few arguments (function, array of initial parameter values, minimization methods,\n",
    "# bounds are the bounds on each parameter; use bounds (same, same) to fix parameter to a single value\n",
    "res = minimize(q_learn_softmax_fit, np.array([0.5, 0.5, 40]), method='SLSQP',\n",
    "               bounds=[(0,1), (0,10), (40,40)], options={'disp':True, 'ftol':1e-16})\n",
    "```\n",
    "\n",
    "### Q4.a (10 punten)\n",
    "\n",
    "Welke parameterwaarden fitten de data van de proefpersoon het beste? Probeer eens een hogere start waarde voor Q values (>80) en hoe beïnvloed dit de model fit? \n",
    "minimize geeft ook de uiteindelijke summed LL (negatief) van het best fittende model. Deze score kan je weer omrekenen naar een gemiddelde likelihood (kans dat model juiste trial koos) per trial. Doe dit, een beoordeel de uitkomst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De parameterwaarden die uit minimize komen zijn $\\alpha =  0.48925202$, $\\theta = 0.23180105$. Een hogere startwaarde voor de Q values resulteert in dezelfde waarden voor $\\alpha$ en $\\theta$. De uiteindelijke summed LL is 56.081857619579395. [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"L4_data_1.txt\") as f:\n",
    "    data = np.loadtxt(f, dtype=int, delimiter=\"\\t\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learn_softmax_fit(params):\n",
    "    alpha, theta, init_value = params\n",
    "    nArms = 4\n",
    "    Q = np.array([[init_value]*nArms])\n",
    "    LL = 0\n",
    "\n",
    "    for row in data:\n",
    "        \n",
    "        # get the softmax values\n",
    "        P = calculate_softmax(Q, theta)\n",
    "\n",
    "        choice = row[1]-1\n",
    "        outcome = row[2]\n",
    "        \n",
    "        LL += np.log(P[0,choice])\n",
    "\n",
    "        Q[0,choice] = update_Q(Q, outcome, 0, choice, alpha)\n",
    "\n",
    "    # Scaled for minimize function\n",
    "    return -1*LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 56.081857619579395\n",
      "            Iterations: 12\n",
      "            Function evaluations: 80\n",
      "            Gradient evaluations: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: 56.081857619579395\n",
       "     jac: array([ 9.53674316e-07, -4.76837158e-07,  4.02761698e+00])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 80\n",
       "     nit: 12\n",
       "    njev: 12\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ 0.48925202,  0.23180105, 40.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize takes a few arguments (function, array of initial parameter values, minimization methods,\n",
    "# bounds are the bounds on each parameter; use bounds (same, same) to fix parameter to a single value\n",
    "res = minimize(q_learn_softmax_fit, np.array([0.5, 0.5, 40]), method='SLSQP',\n",
    "               bounds=[(0,1), (0,10), (40,40)], options={'disp':True, 'ftol':1e-16})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 56.081857619579395\n",
      "            Iterations: 12\n",
      "            Function evaluations: 80\n",
      "            Gradient evaluations: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     fun: 56.081857619579395\n",
       "     jac: array([ 9.53674316e-07, -4.76837158e-07,  4.02761698e+00])\n",
       " message: 'Optimization terminated successfully.'\n",
       "    nfev: 80\n",
       "     nit: 12\n",
       "    njev: 12\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ 0.48925202,  0.23180105, 40.        ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimize takes a few arguments (function, array of initial parameter values, minimization methods,\n",
    "# bounds are the bounds on each parameter; use bounds (same, same) to fix parameter to a single value\n",
    "res = minimize(q_learn_softmax_fit, np.array([0.5, 0.5, 80]), method='SLSQP',\n",
    "               bounds=[(0,1), (0,10), (40,40)], options={'disp':True, 'ftol':1e-16})\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.b (10 punten)\n",
    "\n",
    "Herschrijf de functie nogmaals en zorg ervoor dat de initialisatie van de Q waarde (de start Q waarden) ook een vrije parameter wordt. Als je dit doet kan je de start waarde vinden die het best bij het gedrag van de proefpersoon past. Rapporteer, en interpreteer deze waarde. En zorgt dit ook voor een betere model fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De parameterwaarden die nu uit minimize komen zijn $\\alpha = 0.57894821$, $\\theta = 0.25470942$ en $init\\_value = 24.07207659$. Dit betekent dat de verwachting van de proefpersoon in het begin dus op ongeveer 24 punten moet zitten. De functiewaardie is hier ongeveer 26.01, en bij Q4.a was het 56.08. Dit houdt in dat [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 26.010035104746027\n",
      "            Iterations: 19\n",
      "            Function evaluations: 113\n",
      "            Gradient evaluations: 19\n",
      "     fun: 26.010035104746027\n",
      "     jac: array([1.43051147e-06, 3.33786011e-06, 2.38418579e-07])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 113\n",
      "     nit: 19\n",
      "    njev: 19\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([ 0.57894821,  0.25470942, 24.07207659])\n"
     ]
    }
   ],
   "source": [
    "# minimize takes a few arguments (function, array of initial parameter values, minimization methods,\n",
    "# bounds are the bounds on each parameter; use bounds (same, same) to fix parameter to a single value\n",
    "res = minimize(q_learn_softmax_fit, np.array([0.5, 0.5, 40]), method='SLSQP',\n",
    "               bounds=[(0,1), (0,10), (0,100)], options={'disp':True, 'ftol':1e-16})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.c (10 punten)\n",
    "\n",
    "Als we de functie een klein beetje herschrijven kunnen we deze gebruiken om in het hoofd van de proefpersoon te kijken. Bijvoorbeeld we willen nu weten welke Q-values zij aan de verschillende bandits toekent. \n",
    "\n",
    "Hiervoor is alleen een kleine verandering nodig, waarbij de functie nu niet meer de LogLikelihood als output heeft maar de lijst met Q values. Pas de functie `q_learn_softmax_fit` aan zodat deze de Q-values returnt en noem de nieuwe functie `q_learn_fitted_model`. Zorg hierbij dat de `params` lijst van argumenten ook hetzelfde blijft als bij de `q_learn_softmax_fit`.\n",
    "\n",
    "Nu hoef je ook niet meer de functie fitten of minimalizeren maar alleen aan te roepen, gebruik makende van de beste gevonden `params` van de vorige stap.\n",
    "\n",
    "`q_learn_fitted_model(res.x)`\n",
    "\n",
    "Rapporteer de Q values van deze proefpersoon. In werkelijkheid waren de gemiddelde waardes van den bandits (50, 30, 20, 80). Hoe wijkt de proefpersoon hier van af en hoe is dat te verklaren (hint: kijk naar keuze gedrag, dus de selectie van bandits, in de data file)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De proefpersoon zit dicht in de buurt van de gemiddelde waardes van de bandits. De proefpersoon heeft een afwijking van maximaal 5 punten, en de afwijking is het grootst bij de 2e en 3e schatkist. Dit kan komen doordat de proefpersoon bijna alleen maar voor de 1e en de 4e schatkist heeft gekozen. Hierdoor heeft hij weinig kunnen leren over schatkist 2 en 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learn_fitted_model(params):\n",
    "    alpha, theta, init_value = params\n",
    "    nArms = 4\n",
    "    Q = np.array([[init_value]*nArms])\n",
    "    \n",
    "    for row in data:\n",
    "        \n",
    "        # get the softmax values\n",
    "        P = calculate_softmax(Q, theta)\n",
    "\n",
    "        choice = row[1]-1\n",
    "        outcome = row[2]\n",
    "\n",
    "        Q[0,choice] = update_Q(Q, outcome, 0, choice, alpha)\n",
    "\n",
    "    # Scaled for minimize function\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49.49995203, 25.76719261, 22.29350334, 78.6222417 ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_learn_fitted_model(res.x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
